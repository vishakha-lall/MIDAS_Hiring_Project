{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('submissions_df_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['flair','title_processed','comments_processed','selftext_processed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = 3*dataset['title_processed']+2*dataset['selftext_processed']+dataset['comments_processed']\n",
    "dataset = dataset[['flair','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.assign(**pd.get_dummies(dataset['flair']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_flairs = pd.read_pickle('top_flairs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Non-Political',\n",
       " 'Politics',\n",
       " 'Coronavirus',\n",
       " 'AskIndia',\n",
       " 'Policy/Economy',\n",
       " 'Business/Finance',\n",
       " 'Photography',\n",
       " '[R]eddiquette',\n",
       " 'Sports',\n",
       " 'Science/Technology',\n",
       " 'Others']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flairs = top_flairs.index.to_list()\n",
    "flairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"coronavirus covid-19 megathread news update 4 coronavirus covid-19 megathread news update 4 coronavirus covid-19 megathread news update 4 covid-19 fundraiser donation link amnesty international link cover migrant worker day-labourers vulnerable group urban poor transgender community waste-pickers sanitation worker healthcare worker doctor older person child animal care -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- indian goverment official twitter collection indian govt communication state district wise detail case india india helplines 1075 toll free 1930 toll free 1944 northeast india +911123978046 email id ncov2019 gov.in state helpline number test center list state specific thread reddit community andaman amp nicobar lakshadweep puducherry dadra amp nagar haveli daman amp diu you/thedosaman bihar you/filmmakerfarhan delhi gujarat you/helvetikka karnataka you/theclassicgallery kerala you/nithinvnath madhya pradesh you/maardon_bhenji maharashtra you/hrishidev odisha you/aviakki1 nagaland you/-imsodone- punjab you/thealtchemist rajasthan /you/isaacseaman tamil nadu you/ughalright telangana you/lifehacker25 uttarakhand you/leopard_dopy west bengal /you/ppatra *more state added* coronavirus tracker news update case number indian govt case number map ndtv covid19india.org r/coronavirus r/worldnews r/covid19positive covid-19 patient useful guide precaution helpful tip self assessment safety tip coronavirus condition overview coronavirus q amp protect prepare coronavirus myth buster self assessment tool covid19 coronavirus covid-19 multi-lingual shareable resource wiki wiki thread assamese bengali english gujarati hindi kannada konkani malayalam marathi marwari oriya punjabi tamil telegu urdu r/india community covid-19 india tracker you/splitladoo crowdsourced handbook india specific data resource you/lilhuman0 google spreadsheet statewise infection /you/lord_blood_raven precaution prevention corona virus ^currently ^there ^is ^no ^vaccine ^available ^to ^protect ^against ^human ^corona ^virus ^but ^we ^can ^reduce ^the ^transmission ^of ^virus ^by ^taking ^following ^precautions wash hand regularly 20 second soap water alcohol-based hand rub cover nose mouth disposable tissue flex elbow cough sneeze avoid close contact 1 meter 3 foot people unwell stay home self-isolate household feel unwell touch eye nose mouth hand clean quarantine new york time ^if ^youôçöre ^returning ^from ^an ^area ^thatôçös ^had ^a ^coronavirus ^outbreak ^or ^if ^youôçöve ^been ^in ^close ^contact ^with ^someone ^who ^tests ^positive ^you ^may ^be ^asked ^to ^isolate ^yourself ^at ^home ^for ^two ^weeks ^the ^presumed ^incubation ^period ^for ^the ^coronavirus ^itôçös ^not ^easy ^to ^lock ^yourself ^away ^from ^your ^family ^and ^friends ^these ^are ^the ^basics 1 **isolation** infect exposed coronavirus seclude partner housemates child old aunt pet donôçöt room designate exclusive use visitor itôçös absolutely essential donôçöt bus subway taxi 2 **masks** people ôçö home car youôçöre way doctor youôçöve call ôçö wear mask 3 **hygiene** cover mouth nose tissue cough sneeze discard line trash immediately wash hand soap water 20 second use sanitizer soap water prefer wash hand frequently avoid touch eye nose mouth havenôçöt wash 4 **disinfecting** donôçöt share dish drink glass eat utensils towel bed wash item use use household cleaner wipe countertop tabletop doorknobs bathroom fixture toilet phone keyboard tablet bedside table go surface contaminate bodily fluid 5 **household members** patient wear face mask add glove youôçöre touch carry patientôçös bodily fluid dispose mask glove immediately older member chronic medical condition minimize contact seclude individual -- -- share idle cpu/gpu power find solution covid-19 cpu/gpu sit home yes willing let work drug discovery check fold home follow text /r/pcmasterrace join donate unused gpu cpu compute power fight coronavirus illness like cancer parkinson etc download click learn project need instruction run check -- -- old thread 1 2 3 covid-19 fundraiser donation link amnesty international link cover migrant worker day-labourers vulnerable group urban poor transgender community waste-pickers sanitation worker healthcare worker doctor older person child animal care -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- indian goverment official twitter collection indian govt communication state district wise detail case india india helplines 1075 toll free 1930 toll free 1944 northeast india +911123978046 email id ncov2019 gov.in state helpline number test center list state specific thread reddit community andaman amp nicobar lakshadweep puducherry dadra amp nagar haveli daman amp diu you/thedosaman bihar you/filmmakerfarhan delhi gujarat you/helvetikka karnataka you/theclassicgallery kerala you/nithinvnath madhya pradesh you/maardon_bhenji maharashtra you/hrishidev odisha you/aviakki1 nagaland you/-imsodone- punjab you/thealtchemist rajasthan /you/isaacseaman tamil nadu you/ughalright telangana you/lifehacker25 uttarakhand you/leopard_dopy west bengal /you/ppatra *more state added* coronavirus tracker news update case number indian govt case number map ndtv covid19india.org r/coronavirus r/worldnews r/covid19positive covid-19 patient useful guide precaution helpful tip self assessment safety tip coronavirus condition overview coronavirus q amp protect prepare coronavirus myth buster self assessment tool covid19 coronavirus covid-19 multi-lingual shareable resource wiki wiki thread assamese bengali english gujarati hindi kannada konkani malayalam marathi marwari oriya punjabi tamil telegu urdu r/india community covid-19 india tracker you/splitladoo crowdsourced handbook india specific data resource you/lilhuman0 google spreadsheet statewise infection /you/lord_blood_raven precaution prevention corona virus ^currently ^there ^is ^no ^vaccine ^available ^to ^protect ^against ^human ^corona ^virus ^but ^we ^can ^reduce ^the ^transmission ^of ^virus ^by ^taking ^following ^precautions wash hand regularly 20 second soap water alcohol-based hand rub cover nose mouth disposable tissue flex elbow cough sneeze avoid close contact 1 meter 3 foot people unwell stay home self-isolate household feel unwell touch eye nose mouth hand clean quarantine new york time ^if ^youôçöre ^returning ^from ^an ^area ^thatôçös ^had ^a ^coronavirus ^outbreak ^or ^if ^youôçöve ^been ^in ^close ^contact ^with ^someone ^who ^tests ^positive ^you ^may ^be ^asked ^to ^isolate ^yourself ^at ^home ^for ^two ^weeks ^the ^presumed ^incubation ^period ^for ^the ^coronavirus ^itôçös ^not ^easy ^to ^lock ^yourself ^away ^from ^your ^family ^and ^friends ^these ^are ^the ^basics 1 **isolation** infect exposed coronavirus seclude partner housemates child old aunt pet donôçöt room designate exclusive use visitor itôçös absolutely essential donôçöt bus subway taxi 2 **masks** people ôçö home car youôçöre way doctor youôçöve call ôçö wear mask 3 **hygiene** cover mouth nose tissue cough sneeze discard line trash immediately wash hand soap water 20 second use sanitizer soap water prefer wash hand frequently avoid touch eye nose mouth havenôçöt wash 4 **disinfecting** donôçöt share dish drink glass eat utensils towel bed wash item use use household cleaner wipe countertop tabletop doorknobs bathroom fixture toilet phone keyboard tablet bedside table go surface contaminate bodily fluid 5 **household members** patient wear face mask add glove youôçöre touch carry patientôçös bodily fluid dispose mask glove immediately older member chronic medical condition minimize contact seclude individual -- -- share idle cpu/gpu power find solution covid-19 cpu/gpu sit home yes willing let work drug discovery check fold home follow text /r/pcmasterrace join donate unused gpu cpu compute power fight coronavirus illness like cancer parkinson etc download click learn project need instruction run check -- -- old thread 1 2 3 covid-19 fundraiser donation link amnesty international link cover migrant worker day-labourers vulnerable group urban poor transgender community waste-pickers sanitation worker healthcare worker doctor older person child animal care -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- **i look volunteers** willing create update state level thread time lockdown update consist late news state respect coronavirus ongoing lockdown require volunteer follow state uttar pradesh jammu kashmir ladakh sikkim manipur mizoram assam meghalaya tripura arunachal pradesh jharkhand goa chattisgarh haryana himachal pradesh nagaland andhra pradesh *please reply comment state update daily daily update responsibility volunteer think time maintain coming week thanks -- -- old thread 1 2 3 drove ambulance dug grave mud body shovel `` -dr pradeep kumar bury friend dr simon mob assault `` terrified leave friend '' x200b say maharashtra 66800 test 95 negative positive patient 70 asymptomatic 52 patient critical admitted shortage ppes goa test 826 people declare green zone\\xadƒÿ▓\\xadƒÿ▓\\xadƒÿ▓ karnataka govt crack nanjungud pharma covid19 mystery patient test positive visited china come contact chinese till govt suspect consignment come china pharma company 40 positive mysore pharma company hiranandani hospital charding 50 stipulate covid test fee pretence handling charge shit ... uk people create site track company humanitarian crisis run ethically milk situation covid19india.org great success create similar crowd source site track indian company deserve hall shame carry torch mankind dark hour ~5600 test conduct tn today 49 positive current containment area 82 recover death 4 total ~1000 active case currently get treatment asymptomatic healthy rapid test kit antibody kit distribute district operational tn currently 36,000 rapid kit 24,000 order directly state 12,000 give center 1,95,000 pcr kit 2 automated test machine current mortality rate tn 1.1 icmr current guideline test ili influenza like illness sari severe acute respiratory illness essential worker symptom positive check oxygen saturation multiple time have asymptotic hypoxia take ct scan chest x-rays person discharge 2 consecutive negative test best press conference see good question sensible scientific direct answer bmc take swab sample journalist couple day ago people test positive television journalist surprise see television journalist interview isolation centre return wuhan hopefully sense self isolation singapore extend lockdown 1st june honesty surprise kind extension take place red zone coronavirus hotspot country **navi mumbai- 19 employee company test positive covid-19 ** source merkel explain effect high infection rate countryôçös health system effectively minute less know fact hold phd quantum chemistry explain happen gujarat suddenly report 173 case morning reporting yesterday number late maharashtra housing department issue instruction landlord postpone rent collection month time tenant evict home non payment rent say chief minister endgame case increase social distancing follow plan people work soon sure wave oxford researcher vaccine give hope coronavirus oxford scientist chadox1 vaccine available september work different group philanthropist sure available place need prof gilbert say team work disease x `` give unknown disease go come pandemic future need plan it.ôçø '' chadox1 technology 12 clinical trial conduct different disease consistently good vaccine safety strong immune response single dose vaccine technology rna dna need '' oxford team confident vaccine start manufacture clinical trial delhi hungry people join 2-km-long food queue peak afternoon sun welcome central government bring ordinance end violence health worker carry imprisonment 6 month 7 year find guilty ludhiana north region die corona obese contribute afaik 52 source redditors conditon bad medical college mamc hospital convert dedicated coronavirus hosptial read resident doctor association senior doctor post yesterday trimmer available flipkart order yesterday afternoon deliver today morning bombay delivery boy wear mask delivery usual fact carry lot package delivery society mumbai compulsory download arogya setu app check resident mobile phone breach privacy understand come app particularly safe term user information flipkart start deliver `` non essential item like electronics stationery etc edit live kdmc region maharashtra upwards 60 case district declare red zone know flipkart deliver supply non-essential good e-commerce company remain prohibited lockdown mha new case maharashtra 150 people recover 19 new death 83000 test 8000 test 24 hour total case 5218 death 251 recovery 722. guideline revise mumbai test asymptomatic high risk contact ** source ministry civil aviation clarifies far decision take open domestic international operation airline advise open booking decision regard take government.ôçø recover deceased ratio 5:1 improvement 3:1 day ago recovery increase rapidly great unfortunately cross 500 death cross 13k active case *terrifying scene mcd school delhi jahangirpuri food distribute lockdown friday even stampede young girl kid woman see fall people rush sdm say `` rumour food get cause `` heck happen mp 5 case stop test altogether 10 case karnataka today 0 case bangalore 3rd day row test today 2773 total test till date 26233 mobile phone television refrigerator laptops stationary item allow sell e-commerce platform like amazon flipkart snapdeal april 20 lockdown official scale covid-19 test 5 time 1,500 day karnataka test 300 day headline 1500 day rapid test kit plan reopen monday flipkart begin sell trimmer hair clipper epilator delivery time 3-5 day place order guy number single day recovery death today icmr uploading daily report website maharashtra 4673 test 24 hour 286 people test positive cumulative total test 56673. minute check covid-19 effort covidindiasupport.com good cloudflare setting help small task ping ôçÿdonôçöt passport didnôçöt chinaôçö mysuruôçös patient 52 rameshôçös mother-in-law add faith police investigate case soon possible ôç£i read theory person say son-in-law go china channel say go kerala true ôçø add ôç£i read news article blame read website go china company issue clarification honestly donôçöt know get lie ôçø add jail warden bhondsi jail test positive covid19 return home bhiwani test positive join duty jail come contact chief medical officer gurugram haryana new case maharashtra city wise breakdown tweet mumbai 187 new case vasai virar 22 thane 21 kalyan dombivli 16 pimpri chinchwad 9 mira bhayandar 7 navi mumbai 9 panvel 6 raigad 2 satara solapur bhiwandi nagpur 1 africa epicentre warn bbc news__ sharp rise case past week 1,000 death 18,000 infection africa far rate far low see part europe source government change guideline test find asymptomatic case telangana chief minister announce lockdown till 7 th restriction lift food e-commerce delivery ban till 7th 466 new case maharashtra today 65 new recovery 9 new death total case 4666 recovery 572 death 232 test 76092 test 24 hour 4069. dead page 4 20k +19960 8:23 pm source covid19india.org edit 20k cross 20000+ reinfection report come south korea assume false negative actually contract virus question arises vaccine effective body have repel fully blow virus have produce antibody contract vaccine ensure body safe clinical hope university chicago medicine researcher say saw ôç£rapid recoveriesôçø 125 covid-19 patient take gilead science inc.ôçös experimental drug remdesivir clinical trial man case decrease\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['flair','text']+flairs[:-1]].assign(Others=dataset[dataset.columns.difference(flairs[:-1])].max(1))\n",
    "dataset['text'] = dataset['text'].apply(lambda x: ' '.join([str(elem) for elem in x]))\n",
    "dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset['text'], dataset.loc[:, ~dataset.columns.isin(['flair', 'text'])], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Political</th>\n",
       "      <th>Politics</th>\n",
       "      <th>Coronavirus</th>\n",
       "      <th>AskIndia</th>\n",
       "      <th>Policy/Economy</th>\n",
       "      <th>Business/Finance</th>\n",
       "      <th>Photography</th>\n",
       "      <th>[R]eddiquette</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Science/Technology</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1389 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Non-Political  Politics  Coronavirus  AskIndia  Policy/Economy  \\\n",
       "561               0         0            0         0               0   \n",
       "43                0         0            0         0               1   \n",
       "100               0         0            0         0               0   \n",
       "274               1         0            0         0               0   \n",
       "1265              1         0            0         0               0   \n",
       "...             ...       ...          ...       ...             ...   \n",
       "1130              0         1            0         0               0   \n",
       "1294              0         1            0         0               0   \n",
       "860               0         1            0         0               0   \n",
       "1459              0         0            0         0               1   \n",
       "1126              1         0            0         0               0   \n",
       "\n",
       "      Business/Finance  Photography  [R]eddiquette  Sports  \\\n",
       "561                  0            1              0       0   \n",
       "43                   0            0              0       0   \n",
       "100                  1            0              0       0   \n",
       "274                  0            0              0       0   \n",
       "1265                 0            0              0       0   \n",
       "...                ...          ...            ...     ...   \n",
       "1130                 0            0              0       0   \n",
       "1294                 0            0              0       0   \n",
       "860                  0            0              0       0   \n",
       "1459                 0            0              0       0   \n",
       "1126                 0            0              0       0   \n",
       "\n",
       "      Science/Technology  Others  \n",
       "561                    0       0  \n",
       "43                     0       0  \n",
       "100                    0       0  \n",
       "274                    0       0  \n",
       "1265                   0       0  \n",
       "...                  ...     ...  \n",
       "1130                   0       0  \n",
       "1294                   0       0  \n",
       "860                    0       0  \n",
       "1459                   0       0  \n",
       "1126                   0       0  \n",
       "\n",
       "[1389 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482     mumbai iconic ramzan food market menu time 250...\n",
       "1505    proof india self-driving car technology tesla ...\n",
       "950     social distance vegetable market vijayawada an...\n",
       "1005    catch itôçös late catch itôçös late catch itôç...\n",
       "705     migrant worker migrant worker migrant worker a...\n",
       "                              ...                        \n",
       "584     tvf panchayat authentic rural india portrayal ...\n",
       "310     world learn kerala fight covid-19 world learn ...\n",
       "56      karnataka government decide partially ease loc...\n",
       "513     look get health insurance look get health insu...\n",
       "366     til oscar win song 'jai ho originally compose ...\n",
       "Name: text, Length: 348, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing Non-Political\n",
      "Test accuracy is 0.6609195402298851\n",
      "... Processing Politics\n",
      "Test accuracy is 0.8103448275862069\n",
      "... Processing Coronavirus\n",
      "Test accuracy is 0.8017241379310345\n",
      "... Processing AskIndia\n",
      "Test accuracy is 0.9339080459770115\n",
      "... Processing Policy/Economy\n",
      "Test accuracy is 0.9511494252873564\n",
      "... Processing Business/Finance\n",
      "Test accuracy is 0.9770114942528736\n",
      "... Processing Photography\n",
      "Test accuracy is 0.9626436781609196\n",
      "... Processing [R]eddiquette\n",
      "Test accuracy is 0.9885057471264368\n",
      "... Processing Sports\n",
      "Test accuracy is 0.9885057471264368\n",
      "... Processing Science/Technology\n",
      "Test accuracy is 0.9885057471264368\n",
      "... Processing Others\n",
      "Test accuracy is 0.9396551724137931\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "for flair in flairs:\n",
    "    print('... Processing {}'.format(flair))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(X_train, y_train[flair])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(y_test[flair], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words)), \n",
    "                        ('clf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishakha Lall\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all'...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27011494252873564"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, RF_pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3908523908523908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, RF_pipeline.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishakha Lall\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35337271952388705"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, RF_pipeline.predict(X_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC_pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words)), \n",
    "                        ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all'...\n",
       "                                             'couldn', \"couldn't\", ...},\n",
       "                                 strip_accents=None, sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVC_pipeline.fit(X_train, np.argmax(np.array(y_train), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6551724137931034"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.array(y_test), axis=1), LSVC_pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6551724137931034"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.argmax(np.array(y_test), axis=1), LSVC_pipeline.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Input, LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tokenizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-bcbaabaed6b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'abs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Tokenizer' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(dataset['text'])\n",
    "import pickle\n",
    "with open('tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1186], [19, 2], [1077], [2146], [40], [15], [32947], [40], [11], [4198]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences( ['hello', 'r/india', 'n', 'sacrifice', 'life', 'work', 'witnessed', 'life', 'get', 'destroyed'])\n",
    "tokenizer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_2 = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482     mumbai iconic ramzan food market menu time 250...\n",
       "1505    proof india self-driving car technology tesla ...\n",
       "950     social distance vegetable market vijayawada an...\n",
       "1005    catch itôçös late catch itôçös late catch itôç...\n",
       "705     migrant worker migrant worker migrant worker a...\n",
       "                              ...                        \n",
       "584     tvf panchayat authentic rural india portrayal ...\n",
       "310     world learn kerala fight covid-19 world learn ...\n",
       "56      karnataka government decide partially ease loc...\n",
       "513     look get health insurance look get health insu...\n",
       "366     til oscar win song 'jai ho originally compose ...\n",
       "Name: text, Length: 348, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ecfd78b60946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtext_y_train_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_y_test_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_y_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(text_y_train)\n",
    "text_y_train_enc = encoder.transform(text_y_train)\n",
    "text_y_test_enc = encoder.transform(text_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequence = sequence.pad_sequences(X_train_2, maxlen=80)\n",
    "X_test_sequence = sequence.pad_sequences(X_test_2, maxlen=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  1336,  4728,   227],\n",
       "       [   18,    23,  1634, ...,   540,   429,    86],\n",
       "       [ 5260,   569,   153, ...,    18,  4134,   226],\n",
       "       ...,\n",
       "       [   38,   231,  6730, ...,   298,   125,  7303],\n",
       "       [  770,     3, 21282, ...,    18,  2052,   715],\n",
       "       [  522, 20865,  1012, ...,    85,   522,  1436]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38028"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vishakha Lall\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "embedding_length = 200\n",
    "model = Sequential()\n",
    "model.add(Embedding( len(tokenizer.word_index)+1, embedding_length ,input_length = X_train_sequence.shape[1]))\n",
    "model.add(LSTM(embedding_length, dropout=0.2))\n",
    "model.add(Dense(11,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vishakha Lall\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1389 samples, validate on 348 samples\n",
      "Epoch 1/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 2.1516 - accuracy: 0.2693 - val_loss: 1.9516 - val_accuracy: 0.1897\n",
      "Epoch 2/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 1.8595 - accuracy: 0.3182 - val_loss: 1.8724 - val_accuracy: 0.3764\n",
      "Epoch 3/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 1.6453 - accuracy: 0.5227 - val_loss: 1.7068 - val_accuracy: 0.4828\n",
      "Epoch 4/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 1.1464 - accuracy: 0.6515 - val_loss: 1.6836 - val_accuracy: 0.5201\n",
      "Epoch 5/25\n",
      "1389/1389 [==============================] - 13s 9ms/step - loss: 0.7311 - accuracy: 0.8013 - val_loss: 1.6936 - val_accuracy: 0.5603\n",
      "Epoch 6/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 0.4963 - accuracy: 0.8776 - val_loss: 1.8803 - val_accuracy: 0.5603\n",
      "Epoch 7/25\n",
      "1389/1389 [==============================] - 13s 9ms/step - loss: 0.3128 - accuracy: 0.9057 - val_loss: 1.9204 - val_accuracy: 0.5259\n",
      "Epoch 8/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 0.2027 - accuracy: 0.9424 - val_loss: 2.0322 - val_accuracy: 0.4799\n",
      "Epoch 9/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 0.1056 - accuracy: 0.9734 - val_loss: 2.1787 - val_accuracy: 0.4713\n",
      "Epoch 10/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0731 - accuracy: 0.9820 - val_loss: 2.2238 - val_accuracy: 0.4626\n",
      "Epoch 11/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0372 - accuracy: 0.9942 - val_loss: 2.2585 - val_accuracy: 0.4626\n",
      "Epoch 12/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 2.2111 - val_accuracy: 0.4799\n",
      "Epoch 13/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0258 - accuracy: 0.9942 - val_loss: 2.3194 - val_accuracy: 0.4856\n",
      "Epoch 14/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0296 - accuracy: 0.9950 - val_loss: 2.1793 - val_accuracy: 0.3879\n",
      "Epoch 15/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0381 - accuracy: 0.9914 - val_loss: 2.1529 - val_accuracy: 0.4540\n",
      "Epoch 16/25\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 2.3758 - val_accuracy: 0.4799\n",
      "Epoch 17/25\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 0.0292 - accuracy: 0.9950 - val_loss: 2.1504 - val_accuracy: 0.4655\n",
      "Epoch 18/25\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 0.0279 - accuracy: 0.9935 - val_loss: 2.1661 - val_accuracy: 0.4770\n",
      "Epoch 19/25\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 2.4081 - val_accuracy: 0.4741\n",
      "Epoch 20/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0078 - accuracy: 0.9957 - val_loss: 2.2646 - val_accuracy: 0.4195\n",
      "Epoch 21/25\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0045 - accuracy: 0.9978 - val_loss: 2.2856 - val_accuracy: 0.5029\n",
      "Epoch 22/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 0.0018 - accuracy: 0.9978 - val_loss: 2.3507 - val_accuracy: 0.5086\n",
      "Epoch 23/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 0.0013 - accuracy: 0.9971 - val_loss: 2.4362 - val_accuracy: 0.5086\n",
      "Epoch 24/25\n",
      "1389/1389 [==============================] - 12s 9ms/step - loss: 0.0011 - accuracy: 0.9978 - val_loss: 2.4860 - val_accuracy: 0.5057\n",
      "Epoch 25/25\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 9.2885e-04 - accuracy: 0.9978 - val_loss: 2.5348 - val_accuracy: 0.5029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e87781ea08>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sequence, np.array(y_train), batch_size=64,epochs=25,\n",
    "          validation_data=(X_test_sequence, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_lstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1389 samples, validate on 348 samples\n",
      "Epoch 1/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 8.3744e-04 - accuracy: 0.9978 - val_loss: 2.5512 - val_accuracy: 0.5086\n",
      "Epoch 2/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 7.5747e-04 - accuracy: 0.9993 - val_loss: 2.5718 - val_accuracy: 0.5057\n",
      "Epoch 3/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 6.7987e-04 - accuracy: 0.9978 - val_loss: 2.6239 - val_accuracy: 0.5057\n",
      "Epoch 4/50\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 6.0390e-04 - accuracy: 0.9978 - val_loss: 2.6369 - val_accuracy: 0.5057\n",
      "Epoch 5/50\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 5.8462e-04 - accuracy: 0.9971 - val_loss: 2.6635 - val_accuracy: 0.5144\n",
      "Epoch 6/50\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 5.3320e-04 - accuracy: 0.9971 - val_loss: 2.6959 - val_accuracy: 0.5057\n",
      "Epoch 7/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 4.8987e-04 - accuracy: 0.9978 - val_loss: 2.6775 - val_accuracy: 0.5115\n",
      "Epoch 8/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 4.8708e-04 - accuracy: 0.9986 - val_loss: 2.6960 - val_accuracy: 0.5115\n",
      "Epoch 9/50\n",
      "1389/1389 [==============================] - 13s 9ms/step - loss: 8.4034e-04 - accuracy: 0.9964 - val_loss: 2.7393 - val_accuracy: 0.5029\n",
      "Epoch 10/50\n",
      "1389/1389 [==============================] - 12s 8ms/step - loss: 0.0012 - accuracy: 0.9978 - val_loss: 2.6293 - val_accuracy: 0.4626\n",
      "Epoch 11/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 0.0013 - accuracy: 0.9978 - val_loss: 2.5222 - val_accuracy: 0.4741\n",
      "Epoch 12/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 6.3672e-04 - accuracy: 0.9986 - val_loss: 2.6198 - val_accuracy: 0.4799\n",
      "Epoch 13/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 5.1759e-04 - accuracy: 0.9971 - val_loss: 2.6148 - val_accuracy: 0.4770\n",
      "Epoch 14/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 4.6671e-04 - accuracy: 0.9993 - val_loss: 2.6450 - val_accuracy: 0.4799\n",
      "Epoch 15/50\n",
      "1389/1389 [==============================] - 11s 8ms/step - loss: 4.1862e-04 - accuracy: 0.9971 - val_loss: 2.6995 - val_accuracy: 0.4914\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e8054fe148>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sequence, np.array(y_train), batch_size=64,epochs=50,\n",
    "          validation_data=(X_test_sequence, np.array(y_test)), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['Non-Political',\n",
    " 'Politics',\n",
    " 'Coronavirus',\n",
    " 'AskIndia',\n",
    " 'Policy/Economy',\n",
    " 'Business/Finance',\n",
    " 'Photography',\n",
    " '[R]eddiquette',\n",
    " 'Sports',\n",
    " 'Science/Technology',\n",
    " 'Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non-Political'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
